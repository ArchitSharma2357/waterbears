<!DOCTYPE html>
<html lang="en">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta
    name="description"
    content=""
  />
  
    
      <title>PyTorch Fundamentals: Basics | Tardigrade</title>
    
  
  <link rel="stylesheet" href="/css/reset.css"/>
  <link rel="stylesheet" href="/css/font.css"/>
  <link rel="stylesheet" href="/css/smigle.css"/>
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
</head>
  <body>
    <div id="root">
      <header>
  <div id="brand">
    <a class="icon-link" href="http://localhost:1313/">
      <img
        class="icon"
        src="/images/brandIcon.svg"
      />
    </a>
    <div class="text">
      <a href="http://localhost:1313/"><h1>Tardigrade</h1></a>
      <h3>Veni, Vidi, Coded.</h3>
    </div>
  </div>
  <nav>
    
      
        
        <a href="/"><b>Home</b></a>
      
         | 
        <a href="/about/"><b>About</b></a>
      
         | 
        <a href="/posts/"><b>Posts</b></a>
      
         | 
        <a href="/categories/"><b>Categories</b></a>
      
         | 
        <a href="/tags/"><b>Tags</b></a>
      
         | 
        <a href="/index.xml"><b>RSS</b></a>
      
    
  </nav>
  <hr />
</header>
      <div id="content">
        
  <main>
    <article>
      <h1 class="title">PyTorch Fundamentals: Basics</h1>
      <h3 class="subtitle">Importing PyTorch, creating tensors, and using ndim, item(), and size()</h3>
      <div class="post-meta">
  <strong>
    <span>Posted on</span>
    <time>2025-01-18</time>
    <span>in</span>
    
      <a href="/categories/pytorch">pyTorch</a>
  </strong>
  <span> • 455 words</span>
  <span> • 3 minute read</span>
  
  
    <div>
      <span>Tags:</span>
      
        <a href="/tags/fundamentals">fundamentals</a>
    </div>
  
</div>
      <div class="content"><h2 id="importing-pytorch">Importing PyTorch</h2>
<p>Let&rsquo;s start by importing PyTorch and checking the version we&rsquo;re using.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>import torch
</span></span><span style="display:flex;"><span>torch.__version__
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ae81ff">2.5.1</span><span style="color:#f92672">+</span>cu121
</span></span></code></pre></div><p>It looks like we&rsquo;ve got PyTorch 2.5.1+.</p>
<h2 id="introduction-to-tensors">Introduction to Tensors</h2>
<dl>
<dt>Tensors are multi-dimensional arrays with a uniform type. In machine</dt>
<dt>learning, the term tensor informally refers to two different concepts</dt>
<dd><ol>
<li>a way of organizing data,</li>
<li>a multilinear (tensor)
transformation. Data may be organized in a multidimensional array (M-way
array).</li>
</ol>
</dd>
</dl>
<p>For example, you could represent an image as a tensor with shape
<code>[3, 224, 224]</code> which could mean <code>[colour_channels, height, width]</code>.
Thus, the tensor would have dimensions.</p>
<p>For a detailed explanation of tensors, you can refer to a video by Dan
Fleisch: <a href="https://www.youtube.com/watch?v=f5liqUk0ZTw">What&rsquo;s a
Tensor?</a>.</p>
<h3 id="creating-tensors">Creating Tensors</h3>
<p>There is a whole documentation page for the <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> class.</p>
<p>Let&rsquo;s see a few of the data types which can be defined as :</p>
<ul>
<li>
<p><code>torch.float32</code> or <code>torch.float</code> for 32-bit floating point,</p>
</li>
<li>
<p><code>torch.float64</code> or <code>torch.double</code> for 64-bit floating point, and</p>
</li>
<li>
<p><code>torch.complex64</code> or <code>torch.cfloat</code> for 64-bit complex point.</p>
</li>
</ul>
<p>The first thing we&rsquo;re going to create is a <strong>scalar</strong>.</p>
<p>A scalar is a single number and in tensor-speak it&rsquo;s a zero dimension
tensor.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e"># Scalar
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>scalar <span style="color:#f92672">=</span> torch.<span style="color:#a6e22e">tensor</span>(<span style="color:#ae81ff">7</span>)
</span></span><span style="display:flex;"><span>scalar
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#a6e22e">tensor</span>(<span style="color:#ae81ff">7</span>)
</span></span></code></pre></div><p>That means although <em>scalar</em> is a single number, it&rsquo;s of type
<a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a>.</p>
<p>(Point to note that you can write <code>t</code> in <code>torch.tensor()</code> as <code>T</code> too!)</p>
<p>We can check the dimensions of a tensor using the <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.ndim.html"><code>ndim</code></a> attribute.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>scalar.ndim
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>Now, what if we wanted to retrieve the number from the Tensor?</p>
<p>To do that, we can use the the <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.item.html"><code>item()</code></a> attribute.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e"># Get the Python number within a tensor (only works with one-element tensors)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>scalar.<span style="color:#a6e22e">item</span>()
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ae81ff">7</span>
</span></span></code></pre></div><p>Now, let&rsquo;s see a <strong>vector</strong>.</p>
<p>A vector is a single dimension tensor.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>vector <span style="color:#f92672">=</span> torch.<span style="color:#a6e22e">tensor</span>([<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>])
</span></span><span style="display:flex;"><span>vector
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#a6e22e">tensor</span>([<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">7</span>])
</span></span></code></pre></div><p>You could have a <em>vector</em> <code>[5, 4]</code> to describe <code>[bedrooms, bathrooms]</code> in your house.</p>
<p>Let&rsquo;s check the number of dimensions our vector has :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e"># Check the number of dimensions of vector
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>vector.ndim
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ae81ff">1</span>
</span></span></code></pre></div><p>The number of dimensions of a tensor in PyTorch can be determined by counting the square brackets (<code>[</code> or <code>]</code>) on one side, as they correspond to the tensor&rsquo;s nesting levels.</p>
<p>Let&rsquo;s check that with another example :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>twoDim <span style="color:#f92672">=</span> torch.<span style="color:#a6e22e">tensor</span>([[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>]])
</span></span><span style="display:flex;"><span>twoDim.ndim
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ae81ff">2</span>
</span></span></code></pre></div><p>See, 2 dimensions!</p>
<p>Another important attribute is <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.size.html"><code>size()</code></a>, which used to retrieve the dimensions (shape) of a tensor. It provides the size of each dimension in the tensor, similar to <a href="https://numpy.org/doc/2.1/reference/generated/numpy.ndarray.shape.html"><code>numpy.ndarray.shape</code></a>. This method is particularly useful when you want to know how many elements exist in each dimension of the tensor without modifying it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>sizeDim0 <span style="color:#f92672">=</span> torch.<span style="color:#a6e22e">tensor</span>(<span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>sizeDim1 <span style="color:#f92672">=</span> torch.<span style="color:#a6e22e">tensor</span>([<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>])
</span></span><span style="display:flex;"><span>sizeDim1_moreElements <span style="color:#f92672">=</span> torch.<span style="color:#a6e22e">tensor</span>([[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>], [<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>]]) <span style="color:#75715e">/* It is a matrix, focus on size() for now */</span>
</span></span><span style="display:flex;"><span>sizeDim2 <span style="color:#f92672">=</span> torch.<span style="color:#a6e22e">tensor</span>([[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>]])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sizeDim0.<span style="color:#a6e22e">size</span>(), sizeDim1.<span style="color:#a6e22e">size</span>(), sizeDim1_moreElements.<span style="color:#a6e22e">size</span>(), sizeDim2.<span style="color:#a6e22e">size</span>()
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>(torch.<span style="color:#a6e22e">Size</span>([]), torch.<span style="color:#a6e22e">Size</span>([<span style="color:#ae81ff">2</span>]), torch.<span style="color:#a6e22e">Size</span>([<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>]), torch.<span style="color:#a6e22e">Size</span>([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>]))
</span></span></code></pre></div></div>
    </article>
  </main>

      </div>
      <footer>
  <hr />
  
  <p class="copyright">
    Copyright © 2025
    <strong>Tardigrade</strong>.
  </p>
</footer>
    </div>
  </body>
</html>